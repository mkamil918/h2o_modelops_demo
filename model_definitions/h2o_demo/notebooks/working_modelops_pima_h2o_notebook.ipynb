{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99aa2813",
   "metadata": {},
   "source": [
    "# ModelOps H2O Integration Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3771a",
   "metadata": {},
   "source": [
    "## This notebook is a tutorial on training a model using H2O's AutoML feature, and scoring it in Vantage using BYOM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07622adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mk255125\\AppData\\Roaming\\Python\\Python39\\site-packages\\teradataml\\context\\context.py:484: TeradataMlRuntimeWarning: Warning: Password is URL encoded.\n",
      "  warnings.warn(\"Warning: Password is URL encoded.\", category=TeradataMlRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(teradatasql://mk255125:***@tdprd3.td.teradata.com/?LOGDATA=%2A%2A%2A&LOGMECH=%2A%2A%2A)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from teradataml import create_context\n",
    "import getpass\n",
    "from teradataml import configure\n",
    "\n",
    "host = 'tdprd3.td.teradata.com'\n",
    "username = \"mk255125\"\n",
    "password = getpass.getpass(\"Password:\")\n",
    "val_db = 'TRNG_XSP'\n",
    "byom_db = 'MLDB'\n",
    "\n",
    "configure.val_install_location = val_db\n",
    "configure.byom_install_location = byom_db\n",
    "\n",
    "database = username\n",
    "\n",
    "create_context(host = host,\n",
    "               username=username,\n",
    "               password= password,\n",
    "               logmech=\"TDNEGO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a831c3e",
   "metadata": {},
   "source": [
    "### Load the PIMA dataset into Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8dff490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a334395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a4bb367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumTimesPrg</th>\n",
       "      <th>PlGlcConc</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>TwoHourSerIns</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiPedFunc</th>\n",
       "      <th>Age</th>\n",
       "      <th>HasDiabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NumTimesPrg  PlGlcConc  BloodP  SkinThick  TwoHourSerIns   BMI  \\\n",
       "0              6        148      72         35              0  33.6   \n",
       "1              1         85      66         29              0  26.6   \n",
       "2              8        183      64          0              0  23.3   \n",
       "3              1         89      66         23             94  28.1   \n",
       "4              0        137      40         35            168  43.1   \n",
       "..           ...        ...     ...        ...            ...   ...   \n",
       "763           10        101      76         48            180  32.9   \n",
       "764            2        122      70         27              0  36.8   \n",
       "765            5        121      72         23            112  26.2   \n",
       "766            1        126      60          0              0  30.1   \n",
       "767            1         93      70         31              0  30.4   \n",
       "\n",
       "     DiPedFunc  Age  HasDiabetes  \n",
       "0        0.627   50            1  \n",
       "1        0.351   31            0  \n",
       "2        0.672   32            1  \n",
       "3        0.167   21            0  \n",
       "4        2.288   33            1  \n",
       "..         ...  ...          ...  \n",
       "763      0.171   63            0  \n",
       "764      0.340   27            0  \n",
       "765      0.245   30            0  \n",
       "766      0.349   47            1  \n",
       "767      0.315   23            0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88def951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from teradataml import copy_to_sql\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mk255125\\\\OneDrive - Teradata\\\\Desktop\\\\model_ops_all\\\\pima_dataset.csv\")\n",
    "df.drop(df.columns[0], axis = 1, inplace = True)\n",
    "df.columns = [\"NumTimesPrg\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\", \"Age\", \"HasDiabetes\"]\n",
    "df.drop([\"HasDiabetes\"], axis = 1, inplace = True)\n",
    "copy_to_sql(df = df, table_name = \"PIMA_features\", index=True, index_label=\"PatientId\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2499df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from teradataml import copy_to_sql\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mk255125\\\\OneDrive - Teradata\\\\Desktop\\\\model_ops_all\\\\pima_dataset.csv\")\n",
    "df.drop(df.columns[0], axis = 1, inplace = True)\n",
    "df.columns = [\"NumTimesPrg\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\", \"Age\", \"HasDiabetes\"]\n",
    "df = df[[\"HasDiabetes\"]]\n",
    "\n",
    "copy_to_sql(df = df, table_name = \"PIMA_target\", index=True, index_label=\"PatientId\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9547f",
   "metadata": {},
   "source": [
    "### Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5d9eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import DataFrame\n",
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import os\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# def check_java():\n",
    "#     try:\n",
    "#         print(os.environ['H2O_JAVA_HOME'])\n",
    "#     except:\n",
    "#         print ('Installing Java...')\n",
    "#         import jdk\n",
    "#         jdk.install('17', path='/usr/local/jdk')\n",
    "#         os.environ['H2O_JAVA_HOME'] = '/usr/local/jdk/jdk-17.0.8.1+1'\n",
    "\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    \n",
    "    # read training dataset from Teradata and convert to pandas\n",
    "#     check_java()\n",
    "    h2o.init()\n",
    "    train_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "    train_hdf = h2o.H2OFrame(train_df.to_pandas())\n",
    "\n",
    "    # convert target column to categorical\n",
    "    train_hdf[target_name] = train_hdf[target_name].asfactor()\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "  \n",
    "    # Execute AutoML on training data\n",
    "    aml = H2OAutoML(max_models=context.hyperparams['max_models'], seed=context.hyperparams['seed'])\n",
    "    aml.train(x=feature_names, y=target_name, training_frame=train_hdf)\n",
    "\n",
    "    # Here we are getting the best GBM algorithm for demo purposes\n",
    "    model = aml.get_best_model(algorithm=\"gbm\")\n",
    "    if not model:\n",
    "        model = aml.leader\n",
    "\n",
    "    print(\"Finished training\")\n",
    "    \n",
    "    # export model artefacts\n",
    "    print(\"Test 1\")\n",
    "    mojo = model.download_mojo(path=context.artifact_output_path, get_genmodel_jar=True)\n",
    "    print(\"Printing mojo\")\n",
    "    print(mojo)\n",
    "    print(os.path.abspath(os.getcwd()))\n",
    "    print(context.artifact_output_path)\n",
    "    \n",
    "    new_mojo = os.path.join(os.path.abspath(os.getcwd()), context.artifact_output_path, \"model.h2o\")\n",
    "    print(new_mojo)\n",
    "    if os.path.isfile(new_mojo):\n",
    "        print(\"The file already exists\")\n",
    "    else:\n",
    "        # Rename the file\n",
    "        os.rename(mojo, new_mojo)\n",
    "\n",
    "    print(\"Saved trained model\")\n",
    "\n",
    "    try:\n",
    "        model.varimp_plot(server=True, save_plot_path=os.path.join(os.path.abspath(os.getcwd()), context.artifact_output_path, \"feature_importance.png\"))\n",
    "        fi = model.varimp(True)\n",
    "        fix = fi[['variable','scaled_importance']]\n",
    "        fis = fix.to_dict('records')\n",
    "        feature_importance = {v['variable']:float(v['scaled_importance']) for (k,v) in enumerate(fis)}\n",
    "    except:\n",
    "        print(\"Warning: This model doesn't support feature importance (Stacked Ensemble)\")\n",
    "        aml.varimp_heatmap()\n",
    "        save_plot('Feature Heatmap', context=context)\n",
    "        feature_importance = {}\n",
    "\n",
    "#     record_training_stats(train_df,\n",
    "#                           features=feature_names,\n",
    "#                           targets=[target_name],\n",
    "#                           categorical=[target_name],\n",
    "#                           feature_importance=feature_importance,\n",
    "#                           context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ddaea",
   "metadata": {},
   "source": [
    "### The step below is a way to test the model training function outside of the modelops UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a35f6dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (7 months and 1 day) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 hour 54 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Karachi</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>7 months and 1 day</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_mk255125_h1l17n</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.873 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         1 hour 54 mins\n",
       "H2O_cluster_timezone:       Asia/Karachi\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.1\n",
       "H2O_cluster_version_age:    7 months and 1 day\n",
       "H2O_cluster_name:           H2O_from_python_mk255125_h1l17n\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.873 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.12 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Starting training...\n",
      "AutoML progress: |█\n",
      "17:38:58.329: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n",
      "Finished training\n",
      "Test 1\n",
      "Printing mojo\n",
      "C:\\Users\\mk255125\\OneDrive - Teradata\\Desktop\\model_ops_all\\GBM_1_AutoML_3_20240122_173858.zip\n",
      "C:\\Users\\mk255125\n",
      "C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all\n",
      "C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all\\model.h2o\n",
      "The file already exists\n",
      "Saved trained model\n"
     ]
    }
   ],
   "source": [
    "from aoa import ModelContext, DatasetInfo\n",
    "from teradataml import configure\n",
    "\n",
    "# Define the ModelContext to test with. The ModelContext is created and managed automatically by ModelOps \n",
    "# when it executes your code via CLI / UI. However, for testing in the notebook, you can define as follows\n",
    "\n",
    "# define the training dataset \n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    F.*, T.HasDiabetes\n",
    "FROM PIMA_features F \n",
    "JOIN PIMA_target T\n",
    "ON F.patientid = T.patientid\n",
    "\"\"\"\n",
    "\n",
    "feature_metadata =  {\n",
    "    \"database\": database,\n",
    "    \"table\": \"\"\n",
    "}\n",
    "\n",
    "hyperparams = {\"max_models\": 5, \"seed\": 0}\n",
    "\n",
    "entity_key = \"PatientId\"\n",
    "target_names = [\"HasDiabetes\"]\n",
    "feature_names = [\"NumTimesPrg\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\", \"Age\"]\n",
    " \n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all\",\n",
    "                   model_version=\"v1\",\n",
    "                   model_table=\"aoa_model_v1\")\n",
    "\n",
    "train(context=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf5a3d",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6a3098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from teradataml import DataFrame, copy_to_sql, get_context, H2OPredict\n",
    "from aoa import (\n",
    "    record_evaluation_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    store_byom_tmp,\n",
    "    ModelContext\n",
    ")\n",
    "import json\n",
    "import os\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    with open(f\"{context.artifact_input_path}/model.h2o\", \"rb\") as f:\n",
    "        model_bytes = f.read()\n",
    "\n",
    "    model = store_byom_tmp(get_context(), \"byom_models_tmp\", context.model_version, model_bytes)\n",
    "\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "\n",
    "    byom_target_sql = \"CAST(prediction AS INT)\"\n",
    "\n",
    "    h2o = H2OPredict(\n",
    "        modeldata=model,\n",
    "        newdata=DataFrame.from_query(context.dataset_info.sql),\n",
    "        accumulate=[context.dataset_info.entity_key, target_name]\n",
    "    )\n",
    "\n",
    "    predictions_df = h2o.result\n",
    "\n",
    "    predictions_df.to_sql(table_name=\"predictions_tmp\", if_exists=\"replace\", temporary=True)\n",
    "\n",
    "    metrics_df = DataFrame.from_query(f\"\"\"\n",
    "    SELECT \n",
    "        {target_name} as y_test, \n",
    "        {byom_target_sql} as y_pred\n",
    "        FROM predictions_tmp\n",
    "    \"\"\")\n",
    "    metrics_df = metrics_df.to_pandas()\n",
    "\n",
    "    y_pred = metrics_df[[\"y_pred\"]]\n",
    "    y_test = metrics_df[[\"y_test\"]]\n",
    "\n",
    "    evaluation = {\n",
    "        'Accuracy': '{:.2f}'.format(metrics.accuracy_score(y_test, y_pred)),\n",
    "        'Recall': '{:.2f}'.format(metrics.recall_score(y_test, y_pred)),\n",
    "        'Precision': '{:.2f}'.format(metrics.precision_score(y_test, y_pred)),\n",
    "        'f1-score': '{:.2f}'.format(metrics.f1_score(y_test, y_pred))\n",
    "    }\n",
    "\n",
    "    with open(f\"{context.artifact_output_path}/metrics.json\", \"w+\") as f:\n",
    "        json.dump(evaluation, f)\n",
    "\n",
    "    cf = metrics.confusion_matrix(y_test, y_pred)\n",
    "    display = metrics.ConfusionMatrixDisplay(confusion_matrix=cf)\n",
    "    display.plot()\n",
    "    save_plot('Confusion Matrix', context=context)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=context.model_version)\n",
    "    display.plot()\n",
    "    save_plot('ROC Curve', context=context)\n",
    "\n",
    "    # calculate stats if training stats exist\n",
    "#     if os.path.exists(f\"{context.artifact_input_path}/data_stats.json\"):\n",
    "#         record_evaluation_stats(features_df=DataFrame.from_query(context.dataset_info.sql),\n",
    "#                                 predicted_df=DataFrame(\"predictions_tmp\"),\n",
    "#                                 context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cb28e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': '0.84', 'Recall': '0.90', 'Precision': '0.73', 'f1-score': '0.81'}\n"
     ]
    }
   ],
   "source": [
    "# Define the ModelContext to test with. The ModelContext is created and managed automatically by ModelOps \n",
    "# when it executes your code via CLI / UI. However, for testing in the notebook, you can define as follows\n",
    "\n",
    "# define the evaluation dataset \n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    F.*, D.hasdiabetes \n",
    "FROM PIMA_features F \n",
    "JOIN PIMA_target D\n",
    "ON F.patientid = D.patientid\n",
    "    WHERE D.patientid MOD 5 = 0\n",
    "\"\"\"\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all/\",\n",
    "                   artifact_input_path=\"C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all/\",\n",
    "                   model_version=\"h2oaml_v1\",\n",
    "                   model_table=\"aoa_model_h2oaml_v1\")\n",
    "\n",
    "# drop volatile table from session if executing multiple times\n",
    "try:\n",
    "    get_context().execute(f\"DROP TABLE byom_models_tmp\")\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# import evaluation\n",
    "evaluate(context=ctx)\n",
    "\n",
    "# view evaluation results\n",
    "import json\n",
    "with open(f\"{ctx.artifact_output_path}/metrics.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326acf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6d70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed5d421a",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb7d9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from teradataml import copy_to_sql, get_context, DataFrame, H2OPredict\n",
    "from aoa import (\n",
    "    record_scoring_stats,\n",
    "    aoa_create_context,\n",
    "    store_byom_tmp,\n",
    "    ModelContext\n",
    ")\n",
    "\n",
    "\n",
    "def score(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    with open(f\"{context.artifact_input_path}/model.h2o\", \"rb\") as f:\n",
    "        model_bytes = f.read()\n",
    "\n",
    "    model = store_byom_tmp(get_context(), \"byom_models_tmp\", context.model_version, model_bytes)\n",
    "\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    byom_target_sql = \"CAST(prediction AS INT)\"\n",
    "\n",
    "    print(\"Scoring\")\n",
    "    h2o = H2OPredict(\n",
    "        modeldata=model,\n",
    "        newdata=DataFrame.from_query(context.dataset_info.sql),\n",
    "        accumulate=context.dataset_info.entity_key)\n",
    "\n",
    "    print(\"Finished Scoring\")\n",
    "\n",
    "\n",
    "    # store the predictions\n",
    "    predictions_df = h2o.result\n",
    "    \n",
    "    # add job_id column so we know which execution this is from if appended to predictions table\n",
    "    predictions_df = predictions_df.assign(job_id=context.job_id)\n",
    "    cols = {}\n",
    "    cols[target_name] = predictions_df['prediction']\n",
    "    predictions_df = predictions_df.assign(**cols)\n",
    "    print(predictions_df.head())\n",
    "    predictions_df = predictions_df[[\"job_id\", entity_key, target_name, \"json_report\"]]\n",
    "\n",
    "    copy_to_sql(df=predictions_df,\n",
    "                schema_name=context.dataset_info.predictions_database,\n",
    "                table_name=context.dataset_info.predictions_table,\n",
    "                index=False,\n",
    "                if_exists=\"Replace\")\n",
    "\n",
    "    print(\"Saved predictions in Teradata\")\n",
    "    \n",
    "    # calculate stats\n",
    "    predictions_df = DataFrame.from_query(f\"\"\"\n",
    "        SELECT \n",
    "            * \n",
    "        FROM {context.dataset_info.get_predictions_metadata_fqtn()} \n",
    "            WHERE job_id = '{context.job_id}'\n",
    "    \"\"\")\n",
    "\n",
    "    record_scoring_stats(features_df=DataFrame.from_query(context.dataset_info.sql),\n",
    "                         predicted_df=predictions_df,\n",
    "                         context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf71f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring\n",
      "Finished Scoring\n",
      "   PatientId prediction                                                                                         json_report                                job_id HasDiabetes\n",
      "0         10          0   {\"label\":\"0\",\"labelIndex\":0,\"classProbabilities\":{\"0\":0.7492775606182992,\"1\":0.2507224393817008}}  a99220f1-9040-445f-9834-04538d5f8eec           0\n",
      "1         20          0   {\"label\":\"0\",\"labelIndex\":0,\"classProbabilities\":{\"0\":0.6565814647853214,\"1\":0.3434185352146786}}  a99220f1-9040-445f-9834-04538d5f8eec           0\n",
      "2         25          1   {\"label\":\"1\",\"labelIndex\":1,\"classProbabilities\":{\"0\":0.4816568725679824,\"1\":0.5183431274320176}}  a99220f1-9040-445f-9834-04538d5f8eec           1\n",
      "3         30          1  {\"label\":\"1\",\"labelIndex\":1,\"classProbabilities\":{\"0\":0.47671820589597935,\"1\":0.5232817941040206}}  a99220f1-9040-445f-9834-04538d5f8eec           1\n",
      "4         40          1   {\"label\":\"1\",\"labelIndex\":1,\"classProbabilities\":{\"0\":0.2912646456686089,\"1\":0.7087353543313911}}  a99220f1-9040-445f-9834-04538d5f8eec           1\n",
      "5         45          1   {\"label\":\"1\",\"labelIndex\":1,\"classProbabilities\":{\"0\":0.1546987288167634,\"1\":0.8453012711832366}}  a99220f1-9040-445f-9834-04538d5f8eec           1\n",
      "6         35          0  {\"label\":\"0\",\"labelIndex\":0,\"classProbabilities\":{\"0\":0.8733436449350039,\"1\":0.12665635506499603}}  a99220f1-9040-445f-9834-04538d5f8eec           0\n",
      "7         15          1   {\"label\":\"1\",\"labelIndex\":1,\"classProbabilities\":{\"0\":0.5988113039712484,\"1\":0.4011886960287517}}  a99220f1-9040-445f-9834-04538d5f8eec           1\n",
      "8          5          0  {\"label\":\"0\",\"labelIndex\":0,\"classProbabilities\":{\"0\":0.9034467064958418,\"1\":0.09655329350415817}}  a99220f1-9040-445f-9834-04538d5f8eec           0\n",
      "9          0          1  {\"label\":\"1\",\"labelIndex\":1,\"classProbabilities\":{\"0\":0.25482082025180075,\"1\":0.7451791797481992}}  a99220f1-9040-445f-9834-04538d5f8eec           1\n",
      "Saved predictions in Teradata\n"
     ]
    }
   ],
   "source": [
    "# Define the ModelContext to test with. The ModelContext is created and managed automatically by ModelOps \n",
    "# when it executes your code via CLI / UI. However, for testing in the notebook, you can define as follows\n",
    "\n",
    "# define the scoring dataset \n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    F.*\n",
    "FROM PIMA_FEATURES F \n",
    "    WHERE F.patientid MOD 5 = 0\n",
    "\"\"\"\n",
    "\n",
    "# where to store predictions\n",
    "predictions = {\n",
    "    \"database\": \"mk255125\",\n",
    "    \"table\": \"pima_patient_predictions_tmp\"\n",
    "}\n",
    "\n",
    "import uuid\n",
    "job_id=str(uuid.uuid4())\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata,\n",
    "                           predictions=predictions)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all/\",\n",
    "                   artifact_input_path=\"C:/Users/mk255125/OneDrive - Teradata/Desktop/model_ops_all/\",\n",
    "                   model_version=\"h2oaml_v1\",\n",
    "                   model_table=\"aoa_model_h2oaml_v1\",\n",
    "                   job_id=job_id)\n",
    "\n",
    "# drop volatile table from session if executing multiple times\n",
    "try:\n",
    "    get_context().execute(f\"DROP TABLE byom_models_tmp\")\n",
    "except: \n",
    "    pass\n",
    "\n",
    "score(context=ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
